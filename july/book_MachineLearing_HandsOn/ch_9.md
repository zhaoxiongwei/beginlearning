# 实时机器学习－使用Spring XD框架

想象一下，我们在阅读本章时所大脑里所产生数据量。在大脑中，这些大量的阅读数据，不停经过生成、储存以及处理，
最后得到有用的解读和价值，这就是实时数据。类似的例子很多，比如房间里的温度传感器总是固定产生数据；
再比如，一个处理不同社交媒体的信息源（feed）。这些实时（Real time）产生的数据里面，拥有非常多潜在的价值。
完成获取、处理、保存以及学习这一整个过程，是有复杂很充满难度的。好在现在有一些现成的工具可以帮助我打通整个过程。

本章主要内容是：以Twitter信息流API为例子，说明如何使用Sprint XD框架，开发处理实时数据的机器学习应用。
这个应用例子，可以用来处理Twitter上的实时发帖，并且你可以定制你自己的处理算法。

---
## 获取消防水管式的数据

对那些提供连续的、流式的数据公司，我们经常称他们为消防水管（Firehose）公司。
首先数据就像消防管道的水流一样喷射而出，然后到了接收者这里，获取他们需要的数据，最后经过处理得到最终有用的内容。
当然，这些数据不是随便获取的，有时候数据消费者必须跟数据提供者签订协议。


### 使用实时数据的注意事项

在我们立刻着手开发实时数据应用，扫描Twitter的推文种子（Feed）的之前，我们首先要思考一下，我们的应用是否是真的实时应用？
不能因为我们手里拥有了实时处理工具，我们就一定要开发实时应用。

金融服务公司必须开发实时应用，因为他的客户使用公司提供的服务来决策股票的买卖；这个决策必须是实时的，股票的买卖必须在毫米级做出决定。
以股市为例子，一个滞后10秒或者20秒的数据都是“旧”的，没有处理价值，这是因为在短时间内回产生大量的交易。在这个短时间内，股票价格会发生
多次变动。（译者注：这是机器学习领域重要的应用领域，量化交易或者高频交易。）

相反，电子商务网站就不一定需要开发实时应用。这些网站会周期的（比如3，6，12甚至24小时）批量收集交易数据，
然后利用这些交易数据通过机器学习，形成消费者推荐内容。这些批量数据的处理，我们将在第10章详细介绍。

为了应对实时应用，一些新兴的处理系统，会使用内存数据库。为了得到更快的处理速度，他们不再使用传统的，使用二级存储（译者注：指硬盘）的，
基于ETL模式（Extrac, Transform and Load)的SQL关系数据库，来开发他们的商业智能应用。

另外一个问题就是存储：是否一定需要保存所有数据呢？仅保持处理过的数据能否满足需求？或者是否有保持原始数据，以备后来处理的需求？
尽管存储的成本是在下降的（满足摩尔定理），但是存储依然是你必须考虑的主要成本之一。怎么样保存数据？存储在什么地方？
假如数据保存在云端（比如Amazon S3 )，那么要不要考虑隐私问题呢？你必须思考清楚数据安全（备份、恢复服务水平）以及数据保密（隐私、安全以及访问权限）。

随着计算能力的增长，存储成本的直线下降，我们可以使用很多多高性能、低价格的数据库系统了，甚至无法阻住你同时使用两个或者三个数据库来应对将来的处理。
你可以考虑实现用传统的关系型数据库比如MySQL、基于列存储的数据库比如HBase，又或者图模式数据库比如Neo4J或者Apache Giraffe。
你必须思考清楚你的数据的生命周期、用例，你使用的每一个SQL活着NoSQL数据系统的优缺点（http://martinfowler.com/books /nosql.html）。

### 实时系统的使用范围

实时数据系统的应用非常广泛。随着有价值的社交媒体和手机数据的疯狂增长，实时数据系统变得越来越重要，特别是对那些必须保持即时连接，随时根据人们位置的的变化的推荐系统。
基于位置针对性的广告系统就是非常好的实时系统的例子，这样的系统必须根据消费者的手机位置结合实时场景信息（包括天气、交通、时间以及即时新闻）给出合适的判断。

前面提到的金融交易就是另外一个实时系统的例子。量化交易公司需要高速（微妙级）处理交易的实时计算能力，能够在一秒钟内完成几千次的交易。
有很多的算法能够胜任这样的计算任务。有些系统把财经新闻的头条以及Twitter的种子作为数据源，寻在那些特殊的时机进行交易。
这些实时交易系统取得不同程度的成功。诈骗支付检测算法还可以实时分析交易数据，当这些问题交易发生的时候给指出来。
随着处理能力的增长，这些金融服务公司开始将历史交易数据、位置信息以及在线购买行为都涵盖进来，进行软实时计算，取得更为精准的结果。

为了满足终端用户的交互式响应，系统需要考虑引入实时处理系统。在这样的场景中，总是保持数据在内存中可以提升响应速度。
二级存储只应该被用来加速系统恢复和重启内存，或者用来为深度训练提供大量的数据用。

## 使用 Spring XD
--
本章专门介绍为实时系统而设计的Spring XD框架，该框架大大简化了数据摄取、处理以及输出整个开发流畅。

**注意:** 所谓数据摄取，指的是获得多个源的数据，因此使用Sprint XD可以开发同时处理日志数据、Twitter推文以及RSS种子的应用。

Spring XD可以运行在一台单一的服务器上，也支持以分布式的形式运行在集群上。本章的例子只使用单一的服务器。
Spring XD软件实在Apache 2许可证下发布的开源软件，因此你可以自由下载并且无限制的使用（译者注：必须符合Apache 2许可证）。
Sprint XD涵盖主要的实时数据主要应用方式，是一个用最少的代码快速搭建实时数据分析的不错的起点。

假如你了解UNIX管道命令时如何工作的，那么你将很容易理解Spring XD的工作方式。假如你还不熟悉UNXI的管道命令，
接下来我会解释一下UNIX管道的基础命令以及以及Spring XD中的数据流。

### Spring XD 数据流

Spring XD系统是一个UNIX命令管道流的一个模拟：一个无限长的文本流通过命令过滤，经过某种处理之后把流传递给下一个命令。
比如，在UNIX中，我想在一个或者多个文件中统计字母、单词以及文本行的出现频率，我可以对文件运行cat命令并且把流输出给wc命令：

```cat *.txt | wc```

把这一概念延伸一下，我假如需要在输出结果增加一个带标注的报警提示，我会这样的命令

```cat *.txt | sed 's/^/(lines, words, characters) =/' ```

Spring XD中的数据流工作方式和UNIX命令管道类似。服务器读取输入数据，在不同步骤中处理数据，结果数据被发送到特定目的地。
处理步骤是可选的，但这些处理步骤对机器学习任务来说非常有用。单一的数据流不被仅限于一个处理步骤，数据流可以像链条一样被串联。


在本章的后面，我们提供一个完整的教程，演示了如何配置数据流以及如何处理它们。首先你需要理解管道式数据流的核心组件，以及Spring XD是如何使用的。

### 输入源, 输出目的, 处理单元

Spring XD数据流有三个主要的组件：一个输入源（Input Source), 一个可选的处理单元（Processor），以及一个输出目的（Sink)。

#### 输入源

通过内置的集成适配器（Integration Adaptors），XD系统提供了多种直接使用的输入源。这些输入源涵盖了多种互联网应用协议、日志输出以及文件处理等。
表9-1 总结这些不同类型的输入源：

* **Table 9-1**: Spring XD中不同的输入源

| 输入源名字 | 描述 |
| --------- |:----:|
| HTTP      | 从HTTP请求中读取数据输入，比如，网页，RSS源或者REST API调用 |
| TCP       | 处理TCP socket的输出数据 |
| Mail      | 处理从IMAP服务器读取的到达邮件 |
| JMS       | 从Java Message服务器中读取到达信息 |
| RabbitMQ  | 从RabbitMQ服务器中订阅和读取到达信息 |
| Twitter Stream  | 使用Twitter的数据流API，读取每条推文对应的JSON格式的数据|
| Twitter Search  | 使用Twitter的搜索API，读取每条推文对应的JSON格式的数据|
| File       | 从文件中读取数据 |
| Tail       | 将某个指定的文件的尾输出作为输入数据 |
| MQTT       | 链接MQTT服务器，订阅和接收电报数据 |
| Time       | 触发一个周期的“心跳”时间戳，每个时间戳的值为Spring XD所运行的服务器当前时间，周期是可设置的 |
| Gemfire       | 监听从Gemfire服务器发出的区域事件或者连续查询 |

上面的每一个输入源都携带一个配置信息表，这些配置信息在定义输入源的时候必须设置好。后续章节后将说明如何使用以及配置其中一些输入源。

#### 输出目的

为了最后使用，一个系统必须输出最后的目的数据。最常见的输出目的是日志文件或者数据库表。
Spring XD除了支持日志文件和数据库表之外，也支持一起他输出目的。表9-2列出了这些输出目的。

* **Table 9-2**: Spring XD中的输出目的

| 输入目的名字 | 描述 |
| --------- |:----:|
| File | 输出总是追加到某个文件尾 |
| Log  | 使用内置的日志函数，输出信息按INFO/WARN/ERROR分类，保存为Log4j的形式，并且携带时间戳 |
| JDBC | 讲输出保存到某个关系数据库中，这个数据可以通过JDBC驱动，默认的数据库是基于内存的HSQL |
| Mail | 将输出路由到SMTP邮件服务器 |
| TCP  | 将输出路由到TCP socket，比如把输出路由到 `netcat` UNIX命令 |
| HDFS | 将输出保存到Hadoop分布式文件系统中，第十章将详细说明 |
| RabbitMQ | 将输出发送到RabbitMQ服务器 |
| Splunk Server | Spring XD讲输出转换为SplunkEvent，并通过TCP发送到Splunk服务器 |
| Gemfire Server | 数据将被写入到一个正在运行的Gemfire服务器中，支持标准服务器也支持JSON服务器 |
| MQTT | 输出的电信报文被发送到一个MQTT服务器中 |

在Sprin Integration工程中，也可以创建其他类型的输出目的。

#### 处理单元

到目前为止，本章已经说明了输入和输出的数据类型。你可以很容易的创建Spring XD输入源读取输入数据并且通过管道把他们指定输出到一个输出目睹。
处理单元做位于二者之间，在管道通过数据的时候，允许用户加入自己的数据处理、解析以及分析。
Spring XD内置了多种直接可用的处理单元（查看表9-3）；它们提供基础的过滤、数据拆分以及字符串处理。

* **Table 9-3**: Spring XD 内置的处理单元

| 处理单元名字 | 描述 |
| --------- |:----:|
| Filters | 过滤器，过滤行为类似于grep表达式的作用。过滤器可以是一个Spring Expression Language(SpEL)表达式也可以是一个Groovy脚本|
| JSON Field Value | 保留那些JSON的指定字段值符合匹配值的纪录 |
| JSON Field Extractor | 提取JSON的某些字段的值，并把值做出输出流 |
| Transform | 对输入数据内容做转换作为输出流 |
| Split | 基于表达式，将输入消息分拆为几个数据 |
| Aggregator | 复制多次消息体，生产新的数据 |

尽管Sprin XD已经内置了不少的输入源、输出目的以及处理单元，但是还是大量需要定制的选型，因此我们常常需要开发和创建新的组件。
