{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch下的GPU支持\n",
    "\n",
    "### 1. 支持GPU的张量库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  computeMode : 0\n",
       "  memPitch : 2147483647\n",
       "  canMapHostMemory : 1\n",
       "  warpSize : 32\n",
       "  pciDeviceID : 0\n",
       "  pciBusID : 1\n",
       "  totalConstMem : 65536\n",
       "  pciDomainID : 0\n",
       "  integrated : 0\n",
       "  deviceOverlap : 1\n",
       "  maxThreadsPerBlock : 1024\n",
       "  clockRate : 1032500\n",
       "  maxTexture1D : 65536\n",
       "  minor : 0\n",
       "  name : GeForce GTX 760\n",
       "  freeGlobalMem : 2075398144\n",
       "  maxTexture1DLinear : 134217728\n",
       "  kernelExecTimeoutEnabled : 0\n",
       "  sharedMemPerBlock : 49152\n",
       "  major : 3\n",
       "  totalGlobalMem : 2147287040\n",
       "  regsPerBlock : 65536\n",
       "  textureAlignment : 512\n",
       "  multiProcessorCount : 6\n",
       "}\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require 'cutorch'\n",
    "print(  cutorch.getDeviceProperties(cutorch.getDevice()) )\n",
    "\n",
    "-- 我们默认使用Float，单精度计算\n",
    "torch.setdefaulttensortype('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch支持tensor在CPU/GPU各种的切换，cutorch支持在GPU环境下执行Tensor的各种操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- 在GPU内进行计算\n",
    "t1 = torch.CudaTensor(100):fill(0.5)\n",
    "t2 = torch.CudaTensor(100):fill(1)\n",
    "t1:add(t2)\n",
    "\n",
    "-- GPU和CPU内存切换\n",
    "t1_cpu = t1:float()\n",
    "t1:zero()\n",
    "t1[{}] = t1_cpu  -- copies the data back to the GPU, with no new alloc\n",
    "t1_new = t1_cpu:cuda()  -- allocates a new tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 支持GPU执行环境的神经网络库\n",
    "\n",
    "Torch包含一个GPU执行的神经网络库，这个库和Tensor库的GPU支持一样，接口与GPU版本一样。\n",
    "同样神经网络模型支持CPU与GPU之间的无缝切换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'cunn'\n",
    "\n",
    "ninput = 32\n",
    "noutput = 5\n",
    "-- we define an MLP\n",
    "mlp = nn.Sequential()\n",
    "mlp:add(nn.Linear(ninput, 1000))\n",
    "mlp:add(nn.Tanh())\n",
    "mlp:add(nn.Linear(1000, 1000))\n",
    "mlp:add(nn.Tanh())\n",
    "mlp:add(nn.Linear(1000, 1000))\n",
    "mlp:add(nn.Tanh())\n",
    "mlp:add(nn.Linear(1000, noutput))\n",
    " \n",
    "-- and move it to the GPU:\n",
    "mlp:cuda()\n",
    "\n",
    "\n",
    "input = torch.randn(ninput)\n",
    " \n",
    "-- retype and feed to network:\n",
    "result = mlp:forward( input:cuda() )\n",
    " \n",
    "-- the result is a CudaTensor, if your loss is CPU-based, then you will\n",
    "-- need to bring it back:\n",
    "result_cpu = result:float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
