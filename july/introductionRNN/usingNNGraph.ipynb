{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Torch来构建RNN网络\n",
    "\n",
    "在Torch中可以采用nngraph组件来构建RNN，通过nngraph可以构造复杂结构的多输入、多输出的有向网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true\t\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "require('nngraph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造多输入到单一输出\n",
    "\n",
    "这里构造一个两个向量输入，一个向量输出的简单网络，如下所示：\n",
    "\n",
    "<img src=\"./images/nto1.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- 构造神经网络每个独立的组件\n",
    "linearLayer1 = nn.Linear(3,2)\n",
    "linearLayer2 = nn.Linear(2,2)\n",
    "addLayer = nn.CAddTable()\n",
    "tanhLayer = nn.Tanh()\n",
    "linearLayer3 = nn.Linear(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- 构造多输入到单一输出的网络\n",
    "local inNode1 = linearLayer1()    -- 空括号表示，输入由runtime决定\n",
    "local inNode2 = linearLayer2()\n",
    "local addNode = addLayer({inNode1,inNode2})  -- ()表示输入Node\n",
    "local tanhNode = tanhLayer(addNode)\n",
    "local outNode = linearLayer3(tanhNode)\n",
    "\n",
    "model = nn.gModule({inNode1, inNode2}, {outNode})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1156\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.Tensor({0.1, 1.5, -1.0})\n",
    "x2 = torch.Tensor({-1, 0})\n",
    "local y = model:forward({x1,x2})\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1156\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- 手动检验一下\n",
    "local l1 = linearLayer1:forward(x1)\n",
    "local l2 = linearLayer2:forward(x2)\n",
    "local add = addLayer:forward({l1,l2})\n",
    "local yp = tanhLayer:forward(add)\n",
    "local y = linearLayer3:forward(yp)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  多输入到多输出\n",
    "和之前的例子一样，只是增加一个输出，构造的网路如下所示：\n",
    "\n",
    "<img src=\"./images/nton.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- 构造多输入到多输出的网络\n",
    "local inNode1 = linearLayer1()    -- 空括号表示，输入由runtime决定\n",
    "local inNode2 = linearLayer2()\n",
    "local addNode = addLayer({inNode1,inNode2})  -- ()表示输入Node\n",
    "local tanhNode = tanhLayer(addNode)\n",
    "local outNode = linearLayer3(tanhNode)\n",
    "\n",
    "model = nn.gModule({inNode1, inNode2}, {outNode, addNode})    -- 输出增加一项"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 1\n",
       "  2 : DoubleTensor - size: 2\n",
       "}\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model:forward({x1,x2})\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1156\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n",
       "-0.3330\n",
       "-1.1955\n",
       "[torch.DoubleTensor of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y[1], y[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  构造递归结构\n",
    "\n",
    "由于我们得到了中间变量的输出，因此可以把中间变量给输出到下一次的输入中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6251\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n",
       "-0.5163\n",
       "[torch.DoubleTensor of size 1]\n",
       "\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local h0 = torch.rand(2)\n",
    "local x_t0 = torch.rand(3)\n",
    "local out_t1 = model:forward({x_t0, h0})\n",
    "\n",
    "print(out_t1[1])\n",
    "\n",
    "local x_t1 = torch.rand(3)\n",
    "local h1 = out_t1[2]                -- 得到h1项\n",
    "local out_t2 = model:forward({x_t1, h1}) \n",
    "\n",
    "print(out_t2[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
