{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1: 机器学习框架 Torch 介绍\n",
    "\n",
    "Torch 是一个以机器学习为核心的科学计算框架。由于采用了高效的脚本语言LuaJIT，同时提供了一个灵活的交互计算环境，因此，Torch 特别适合用来开发机器学习相关任务。此外Torch对C/CUDA支持非常好，因此也能很好的胜任大规模的计算任务，如深度学习的训练。\n",
    "\n",
    "关键的特征：\n",
    "\n",
    "* 一个强大的张量库（Tensor,N-dimensional array），支持各种下标、切片访问以及变换\n",
    "* 完整的线性代数支持，类似于Matlab的接口\n",
    "* 集成了state of art的神经网络、概率图模型实现\n",
    "* 集成常规的数值优化计算\n",
    "* 友好的交互计算，可视化支持\n",
    "* 非常容易集成C语言开发本地代码\n",
    "* 对CUDA支持非常友好\n",
    "* 容易移植到iOS, Android等终端平台\n",
    "\n",
    "![frameworks](./images/frameworks.png)\n",
    "\n",
    "```\n",
    "$ th\n",
    "\n",
    "  ______             __   |  Torch7                                   \n",
    " /_  __/__  ________/ /   |  Scientific computing for Lua.         \n",
    "  / / / _ \\/ __/ __/ _ \\  |                                           \n",
    " /_/  \\___/_/  \\__/_//_/  |  https://github.com/torch   \n",
    "                          |  http://torch.ch   \n",
    "                        \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 基础的矩阵计算演示\n",
    "\n",
    "下面是最常用的矩阵计算函数:\n",
    "\n",
    "* rand() which creates tensor drawn from uniform distribution\n",
    "* t() which transposes a tensor (note it returns a new view)\n",
    "* dot() which performs a dot product between two tensors\n",
    "* eye() which returns a identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "-- 构造一个5x5的随机矩阵\n",
    "N = 5\n",
    "A = torch.rand(N, N)\n",
    "print(A) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码输出对称矩阵\n",
    "$$\n",
    "A = A * A^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = A*A:t()\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面代码实现计算：矩阵乘向量，即列向量的线性组合。\n",
    "\n",
    "$$\n",
    "  B = A * v\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v = torch.rand(5,1)\n",
    "B = A*v\n",
    "print(\"v=\")\n",
    "print(v)\n",
    "print(\"B=\")\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算反矩阵：\n",
    "\n",
    "$$\n",
    "C = A^{-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C = torch.inverse(A)\n",
    "print(C)\n",
    "print(C*A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 可视化演示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "require('image')\n",
    "itorch.image({image.lena(), image.lena(), image.lena()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "require ('nn')\n",
    "-- 利用神经网络构造一个随机的3x3x3滤波器，对RGB图像进行进行滤波操作\n",
    "m=nn.SpatialConvolution(3,1,3,3)\n",
    "n=m:forward(image.lena())\n",
    "itorch.image(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Plot = require 'itorch.Plot'\n",
    "x1 = torch.randn(40):mul(100)\n",
    "y1 = torch.randn(40):mul(100)\n",
    "x2 = torch.randn(40):mul(100)\n",
    "y2 = torch.randn(40):mul(100)\n",
    "x3 = torch.randn(40):mul(200)\n",
    "y3 = torch.randn(40):mul(200)\n",
    "plot = Plot():circle(x1, y1, 'red', 'hi'):circle(x2, y2, 'blue', 'bye'):draw()\n",
    "plot:circle(x3,y3,'green', 'yolo'):redraw()\n",
    "plot:title('Scatter Plot Demo'):redraw()\n",
    "plot:xaxis('length'):yaxis('width'):redraw()\n",
    "plot:legend(true)\n",
    "plot:redraw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 梯度下降算法演示\n",
    "\n",
    "Torch支持多种数值计算优化算法，包括SGD, Adagrad, Conjugate-Gradient, LBFGS, RProp等等。\n",
    "\n",
    "This package contains several optimization routines for Torch. Each optimization algorithm is based on the same interface:\n",
    "```\n",
    "x*, {f}, ... = optim.method(func, x, state)\n",
    "```\n",
    "where:\n",
    "\n",
    "* ```func```: a user-defined closure that respects this API: ```f, df/dx = func(x)```\n",
    "* ```x```: the current parameter vector (a 1D torch.Tensor)\n",
    "* ```state```: a table of parameters, and state variables, dependent upon the algorithm\n",
    "* ```x*```: the new parameter vector that minimizes ```f, x* = argmin_x f(x)```\n",
    "* ```{f}```: a table of all f values, in the order they've been evaluated (for some simple algorithms, like SGD, ```#f == 1```)\n",
    "\n",
    "这里设计一个一维的线性回归，即直线拟合的例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "-- 构造训练样本\n",
    "N = 32\n",
    "x = {}\n",
    "y = {}\n",
    "for i=1, N do\n",
    "    x[i] = (math.random() - 0.5) * 20\n",
    "    y[i] = 0.7*x[i] + 5.0 + (math.random()-0.5) \n",
    "end\n",
    "\n",
    "Plot = require 'itorch.Plot'\n",
    "local plot = Plot()\n",
    "plot:circle(x,y,'black', 'yolo'):draw()\n",
    "plot:title('直线拟合'):redraw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "require('optim')\n",
    "\n",
    "-- 纪录输出日志\n",
    "batchLog = {}\n",
    "batchLog.value = {}\n",
    "batchLog.seq = {}\n",
    "\n",
    "parameter = torch.Tensor(2)\n",
    "parameter[1] = 0\n",
    "parameter[2] = 0\n",
    "\n",
    "-- 首先构造 func(x)\n",
    "function batchFunc(inParameter) \n",
    "  \n",
    "  local sum = 0.0\n",
    "  local deltaP = torch.Tensor(2)\n",
    "    \n",
    "  deltaP[1] = 0.0\n",
    "  deltaP[2] = 0.0\n",
    "  for i=1,#x do\n",
    "    sum = sum + math.pow(inParameter[1] * x[i] + inParameter[2] - y[i],2)\n",
    "    deltaP[1] = deltaP[1] + (inParameter[1] * x[i] + inParameter[2] - y[i]) * x[i]\n",
    "    deltaP[2] = deltaP[2] + (inParameter[1] * x[i] + inParameter[2] - y[i])\n",
    "  end\n",
    "  sum = 0.5 * sum / #x\n",
    "  deltaP = deltaP / #x\n",
    "\n",
    "  batchLog.value[#batchLog.value+1] = sum\n",
    "  batchLog.seq[#batchLog.seq+1] = #batchLog.seq+1\n",
    "    \n",
    "  return sum , deltaP\n",
    "end\n",
    "\n",
    "\n",
    "local state = {\n",
    "   learningRate = 1.0e-2,\n",
    "}\n",
    "\n",
    "for i = 1,500 do\n",
    "  optim.sgd(batchFunc, parameter ,state)\n",
    "end\n",
    "\n",
    "local plot = Plot()\n",
    "plot:line(batchLog.seq, batchLog.value,'black', 'yolo'):draw()\n",
    "plot:title('BGD'):redraw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "-- 绘制拟合出来的直线\n",
    "drawResultLine = function()\n",
    "  local resultValue = {}\n",
    "  local resultSeq = {}\n",
    "  for i=-10,10,0.1 do\n",
    "    resultSeq[#resultSeq+1] = i\n",
    "    resultValue[#resultValue+1] = i*parameter[1] + parameter[2]\n",
    "  end\n",
    "  local plot = Plot()\n",
    "  plot:circle(x,y,'red', 'yolo'):draw()\n",
    "  plot:line(resultSeq, resultValue,'black', 'yolo'):redraw()\n",
    "  plot:title('直线拟合'):redraw()\n",
    "    \n",
    "end\n",
    "drawResultLine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上面的曲线可以看出，设置learningRate非常重要，下面演示一下SGD算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require('optim')\n",
    "\n",
    "-- 纪录输出日志\n",
    "sgdLog = {}\n",
    "sgdLog.value = {}\n",
    "sgdLog.seq = {}\n",
    "\n",
    "parameter[1] = 0\n",
    "parameter[2] = 0\n",
    "\n",
    "local sgdNumber = 0\n",
    "\n",
    "-- 首先构造 func(x)\n",
    "function sgdFunc(inParameter) \n",
    "  \n",
    "  local sum = 0.0\n",
    "  local deltaP = torch.Tensor(2)\n",
    "    \n",
    "    \n",
    "  sgdNumber = (sgdNumber + 1) % #x\n",
    "  local i = sgdNumber + 1\n",
    "    \n",
    "  sum = 0.5 * math.pow(inParameter[1] * x[i] + inParameter[2] - y[i],2)\n",
    "  deltaP[1] = (inParameter[1] * x[i] + inParameter[2] - y[i]) * x[i]\n",
    "  deltaP[2] = (inParameter[1] * x[i] + inParameter[2] - y[i])\n",
    "    \n",
    "  sgdLog.value[#sgdLog.value+1] = sum\n",
    "  sgdLog.seq[#sgdLog.seq+1] = #sgdLog.seq+1\n",
    "    \n",
    "  return sum , deltaP\n",
    "end\n",
    "\n",
    "\n",
    "local state = {\n",
    "   learningRate = 1.0e-2,\n",
    "}\n",
    "\n",
    "for i = 1,200 do\n",
    "  optim.sgd(sgdFunc, parameter ,state)\n",
    "end\n",
    "\n",
    "local plot = Plot()\n",
    "plot:line(sgdLog.seq, sgdLog.value,'black', 'yolo'):draw()\n",
    "plot:title('SGD'):redraw()\n",
    "\n",
    "drawResultLine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
