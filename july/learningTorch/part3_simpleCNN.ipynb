{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3: 深度卷积网络演示\n",
    "\n",
    "在Part2部分，我们实验了自己开发基于Torch的算法。在这一部分，我们直接使用Torch带的强大的神经网络实现包，实验一个与LeNet类似的卷积网络，识别一张64x64的手势图像。\n",
    "\n",
    "### 0. 装载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_CUDA_ = false\n",
    "\n",
    "require('image')\n",
    "require('./guestureData')\n",
    "\n",
    "torch.setdefaulttensortype('torch.FloatTensor')\n",
    "\n",
    "print('总样本数目：'.. #allSamples)\n",
    "local guestures = {};\n",
    "for i=1,36 do\n",
    "    guestures[i] = image.loadPNG( allSamples[i].fileName, 3 );\n",
    "end\n",
    "itorch.image(guestures)\n",
    "\n",
    "sampleLabel = {'A', 'B', 'C', 'Five', 'Point', 'V'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 构造训练样本和测试样本\n",
    "\n",
    "这里设置400个测试样本，2000个训练样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if ( _CUDA_) then\n",
    "require('cunn')\n",
    "end\n",
    "\n",
    "\n",
    "trainSamples = {}\n",
    "for i = 1,2000 do\n",
    "    allSamples[i].data = image.loadPNG( allSamples[i].fileName, 3 )\n",
    "    allSamples[i].data = (allSamples[i].data-0.5)*2\n",
    "    if (_CUDA_) then\n",
    "        allSamples[i].data = allSamples[i].data:cuda()\n",
    "    end\n",
    "    trainSamples[i] = allSamples[i]\n",
    "end\n",
    "\n",
    "testSamples = {}\n",
    "for i = 2001,2400 do\n",
    "    allSamples[i].data = image.loadPNG( allSamples[i].fileName, 3 )\n",
    "    allSamples[i].data = (allSamples[i].data-0.5)*2\n",
    "    if (_CUDA_) then\n",
    "        allSamples[i].data = allSamples[i].data:cuda()\n",
    "    end\n",
    "    testSamples[i-2000] = allSamples[i]\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 设计卷积网络\n",
    "\n",
    "卷积网络的不同于全连接网络，卷积层把输入看作二维多张图像，在X-Y面做滑动卷积，Z方向做线性组合，典型如图所示：\n",
    "![卷积网络形式](./images/cnn.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require('nn')\n",
    "    \n",
    "-- 构造一个卷积网络\n",
    "model = nn.Sequential()\n",
    "model:add(nn.SpatialConvolution(3, 8, 3, 3, 1, 1, 1)) \n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2))\n",
    "model:add(nn.SpatialConvolution(8, 16, 3, 3, 1, 1, 1))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2))\n",
    "model:add(nn.SpatialConvolution(16, 16, 3, 3, 1, 1, 1))\n",
    "model:add(nn.ReLU())\n",
    "model:add(nn.SpatialMaxPooling(2, 2))\n",
    "model:add(nn.Reshape(16*8*8))\n",
    "model:add(nn.Linear(16*8*8, 6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 设计训练方法\n",
    "\n",
    "#### 3.1 设计Loss Function\n",
    "\n",
    "这里使用 softmax 输出，相关计算如下：\n",
    "\n",
    "$$\n",
    "P(Y=i|x^n,W,b) = \\text{softmax}(Wx^n+be) = \\frac{ e^{Wx_i^n+b} }{ \\sum_j e^{Wx_j^n+b} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- 配合LogSoftMax使用的loss function\n",
    "model:add(nn.LogSoftMax())\n",
    "\n",
    "model:training()\n",
    "criterion = nn.ClassNLLCriterion() \n",
    "\n",
    "if (_CUDA_) then\n",
    "    model:cuda()\n",
    "    criterion:cuda()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 设计训练函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batchSize = 32\n",
    "itemIndex = 1\n",
    "\n",
    "-- 纪录模型的参数\n",
    "parameters,gradParameters = model:getParameters()\n",
    "doTrain = function(x)\n",
    "  -- get new parameters\n",
    "  if x ~= parameters then\n",
    "    parameters:copy(x)\n",
    "  end\n",
    "  -- reset gradients\n",
    "  gradParameters:zero()\n",
    "  \n",
    "  local f = 0 --error均值 \n",
    "  for i=0,batchSize-1 do\n",
    "    local targetIndex = (itemIndex + i) % #trainSamples + 1\n",
    "    local targetSample = trainSamples[targetIndex].data\n",
    "        \n",
    "    -- 前向计算    \n",
    "    local output = model:forward(targetSample)\n",
    "    local err = criterion:forward(output, trainSamples[targetIndex].y)\n",
    "    f = f + err\n",
    "    \n",
    "    -- 后向计算估计 df/dw\n",
    "    local df_do = criterion:backward(output, trainSamples[targetIndex].y)\n",
    "    model:backward(targetSample, df_do)    \n",
    "  end\n",
    "  \n",
    "  gradParameters:div(batchSize)\n",
    "  f = f/batchSize \n",
    "  \n",
    "  return f, gradParameters\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 设计优化算法\n",
    "\n",
    "这里可以尝试使用sgd, asgd，adadelta等不同的优化算法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require('optim')\n",
    "\n",
    "optimMethod = optim.adadelta\n",
    "optimState = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 训练卷积网络\n",
    "#### 4.1 试训练\n",
    "\n",
    "我们首先固定一个小样本，进行训练，确保模型能够收敛，以下演示了一个试训练的过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local maxLoop = 30\n",
    "local errRecord = {  --纪录每次训练的error输出\n",
    "  seq = {},\n",
    "  value = {}\n",
    "}\n",
    "\n",
    "optimState = {}\n",
    "itemIndex = 1\n",
    "for i=1,maxLoop do\n",
    "  local err\n",
    "  _, err = optimMethod(doTrain, parameters, optimState)\n",
    "  \n",
    "  errRecord.value[i] = err\n",
    "  errRecord.seq[i] = i\n",
    "end\n",
    "\n",
    "Plot = require 'itorch.Plot'\n",
    "local plot = Plot()\n",
    "plot:line(errRecord.seq, errRecord.value,'black', 'yolo'):draw()\n",
    "plot:title(\"小样本测试\"):redraw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 全样本训练，以及测试集监控\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainRecord = {  --纪录每次训练的error输出\n",
    "  seq = {},\n",
    "  value = {}\n",
    "}\n",
    "\n",
    "testRecord = {\n",
    "   value = {},\n",
    "   pred = {}\n",
    "}\n",
    "\n",
    "oneEpochs = function() \n",
    "    local maxLoop = math.floor(#trainSamples/batchSize)\n",
    "    itemIndex = 1\n",
    "    \n",
    "    local err\n",
    "    for i= 1, maxLoop+1 do\n",
    "      _, err = optimMethod(doTrain, parameters, optimState)\n",
    "      \n",
    "      itemIndex = itemIndex + batchSize\n",
    "      if (itemIndex > #trainSamples) then\n",
    "          itemIndex = 1\n",
    "      end\n",
    "        \n",
    "      trainRecord.value[#trainRecord.value+1] = err\n",
    "      trainRecord.seq[#trainRecord.seq+1] = #trainRecord.seq+1  \n",
    "    end    \n",
    "end\n",
    "\n",
    "doTest = function()\n",
    "  local f = 0\n",
    "  local rightPred = 0\n",
    "  local pred\n",
    "  for i=1, #testSamples do \n",
    "    local targetSample = testSamples[i].data\n",
    "    local output = model:forward(targetSample)\n",
    "    \n",
    "    _, pred = torch.max(output, 1)\n",
    "    \n",
    "    if ( pred[1] == testSamples[i].y ) then \n",
    "        rightPred = rightPred + 1\n",
    "    end\n",
    "        \n",
    "    local err = criterion:forward(output, testSamples[i].y)\n",
    "    f = f + err    \n",
    "  end\n",
    "  f = f / #testSamples\n",
    "    \n",
    "  table.insert(testRecord.value, f)\n",
    "  table.insert(testRecord.pred, rightPred)\n",
    "    \n",
    "  return f, rightPred\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- trainRecord.seq = {}\n",
    "-- trainRecord.value = {}\n",
    "-- optimState = {}\n",
    "\n",
    "local beginT = sys.clock()\n",
    "oneEpochs()\n",
    "doTest()\n",
    "local endT = sys.clock()\n",
    "\n",
    "print(\">>>执行时间：\" .. (endT-beginT))\n",
    "\n",
    "local plot = Plot()\n",
    "plot:line(trainRecord.seq, trainRecord.value,'black', 'yolo'):draw()\n",
    "plot:title(\"全样本测试\"):redraw()\n",
    "\n",
    "for i=1, #testRecord.value do\n",
    "  print(\"Epoches:\" .. i .. \" loss=\" .. testRecord.value[i] .. \" pred=\" .. (testRecord.pred[i]/#testSamples) )\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 可视化测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local testImages = {}\n",
    "local testResult = {}\n",
    "local testValue = {}\n",
    "for i = 1,6 do\n",
    "    local index = math.floor( math.random() * #testSamples) + 1\n",
    "    local targetSample = testSamples[index].data\n",
    "    local output = model:forward(targetSample)\n",
    "    local result\n",
    "    \n",
    "    _, result = torch.max(output, 1)\n",
    "    \n",
    "    table.insert(testValue, testSamples[index].y )\n",
    "    table.insert(testImages, targetSample)\n",
    "    table.insert(testResult, result)\n",
    "end\n",
    "\n",
    "itorch.image(testImages)\n",
    "for i = 1, #testResult do\n",
    "    print(i .. \">>>>>>>>>>>: \" .. sampleLabel[testValue[i]] ..\" *** \".. sampleLabel[testResult[i][1]] )\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language": "lua",
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
